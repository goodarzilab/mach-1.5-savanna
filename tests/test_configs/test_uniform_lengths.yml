# Minimal config to test dataloading equal-length samples.
{
  "seq_length": 18,
  "enforce_sample_length": True,

  "train-data-paths": ["tests/data/test_uniform_lengths_pad_eod_text_CharLevelTokenizer_document"],
  "test-data-paths": ["tests/data/test_uniform_lengths_pad_eod_text_CharLevelTokenizer_document"],
  "valid-data-paths": ["tests/data/test_uniform_lengths_pad_eod_text_CharLevelTokenizer_document"],
  "test-data-weights": [1.],
  "valid-data-weights": [1.],

  "pipe_parallel_size": 0,
  "model_parallel_size": 1,
  "make_vocab_size_divisible_by": 8,

  "train_micro_batch_size_per_gpu": 1,
  "gradient_accumulation_steps": 1,

  "num_layers": 0,
  "hidden_size": 1,
  "num_attention_heads": 1,

  "train-iters": 15,
  "eval-interval": 1,
  "eval-iters": 5,
  "iteration": 0,

  "data-impl": "mmap",
  "tokenizer_type": CharLevelTokenizer,
}
