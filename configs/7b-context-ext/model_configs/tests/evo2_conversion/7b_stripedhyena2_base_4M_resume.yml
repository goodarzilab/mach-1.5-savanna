min_lr: 3.0e-06
optimizer:
  params:
    betas:
    - 0.9
    - 0.95
    eps: 1.0e-08
    lr: 0.00003
  type: Adam

attention-dropout: 0.0

bf16:
  enabled: true
bias-gelu-fusion: false
bias_dropout_fusion: false
cgcg_bwd_autotune: true
cgcg_bwd_kernel_config_post_conv_block_x: 32
cgcg_bwd_kernel_config_post_conv_block_y: 128
cgcg_bwd_kernel_config_post_conv_num_warps: 4
cgcg_bwd_kernel_config_pre_conv_block_x: 128
cgcg_bwd_kernel_config_pre_conv_block_y: 128
cgcg_bwd_kernel_config_pre_conv_num_warps: 8
cgcg_dtype: bfloat16
cgcg_fused_bwd: true
cgcg_fwd_autotune: false
cgcg_medium_fwd_kernel_config_block_d: 128
cgcg_medium_fwd_kernel_config_chunk_size: 128
cgcg_medium_fwd_kernel_config_chunk_tiles_per_program: 1
cgcg_medium_fwd_kernel_config_num_stages: 3
cgcg_medium_fwd_kernel_config_threadblock_swizzle: row
cgcg_short_fwd_kernel_config_block_d: 128
cgcg_short_fwd_kernel_config_chunk_size: 128
cgcg_short_fwd_kernel_config_chunk_tiles_per_program: 1
cgcg_short_fwd_kernel_config_num_stages: 1
cgcg_short_fwd_kernel_config_num_warps: 4
cgcg_short_fwd_kernel_config_threadblock_swizzle: row
checkpoint-activations: true
checkpoint-factor: 5000
checkpoint-num-layers: 4

checkpoint_strict_load: false
data-impl: mmap
distributed-backend: nccl
eval-interval: 200
eval-iters: 20
explicit_filter_decay_preset: weak
fast_conv_proj: true
gpt_j_residual: false
gradient_accumulation_steps: 1
gradient_clipping: 1.0
hidden-dropout: 0.0
hidden_size: 4096
hyena_filter_cls: implicit_modal
hyena_filter_fast_decay: 0.3
hyena_filter_order: 16
hyena_filter_slow_decay: 1.2
hyena_filter_w: 14
hyena_filter_wd: 0.0
hyena_mr_len: 128
hyena_medium_filter_cls: explicit_single_decay
hyena_mlp_len: 7
hyena_se_len: 7
identity_mlp: false
init_method: small_init
keep-last-n-checkpoints: 2
log-interval: 5
log_attn_norms: false
lowercase_loss_reweighting: 0.1
lr-decay-iters: 500000
lr-decay-style: cosine
make_gated_mlp_multiple_of: 128
make_vocab_size_divisible_by: 8
mask_loss_control_tags: true
materialize_attn_mask: false
max_position_embeddings: 8192

mlp_type: llama
model_parallel_size: 1
no_weight_tying: false
norm: rmsnorm
normalize_hyena_filters: false
num_attention_heads: 32
num_groups_hyena: 4096
num_groups_hyena_medium: 256
num_groups_hyena_mlp: 256
num_groups_hyena_short: 256
num_layers: 32
operator-config:
- - - hyena_se
  - 1
- - - hyena_mr
  - 1
- - - hyena
  - 1
- - - flash_v2
  - 1
- - - hyena_se
  - 1
- - - hyena_mr
  - 1
- - - hyena
  - 1
- - - hyena_se
  - 1
- - - hyena_mr
  - 1
- - - hyena
  - 1
- - - flash_v2
  - 1
- - - hyena_se
  - 1
- - - hyena_mr
  - 1
- - - hyena
  - 1
- - - hyena_se
  - 1
- - - hyena_mr
  - 1
- - - hyena
  - 1
- - - flash_v2
  - 1
- - - hyena_se
  - 1
- - - hyena_mr
  - 1
- - - hyena
  - 1
- - - hyena_se
  - 1
- - - hyena_mr
  - 1
- - - hyena
  - 1
- - - flash_v2
  - 1
- - - hyena_se
  - 1
- - - hyena_mr
  - 1
- - - hyena
  - 1
- - - hyena_se
  - 1
- - - hyena_mr
  - 1
- - - hyena
  - 1
- - - flash_v2
  - 1

outer_mlp_norm: false
output_layer_init_method: wang_init
output_layer_parallelism: column
partition-activations: true
pipe_parallel_size: 0
pos_emb: rotary
postnorm: false
pre_mlp_norm: true
precision: bfloat16
prenorm: true
rms_norm_epsilon: 1.0e-06
rotary_pct: 1
# save: /lustre/fs01/portfolios/dir/projects/dir_arc/evo/checkpoints/7b-ablations-n32/7b_stripedhyena2_base_4M_resume/202410210618
load: /lustre/fs01/portfolios/dir/projects/dir_arc/evo/checkpoints/7b-ablations-n32/7b_stripedhyena2_base_4M_resume/202410210618
scaled-upper-triang-masked-softmax-fusion: true
seq_length: 8192
short-conv-L: 3
srun_launcher_type: srun
steps_per_print: 5
synchronize-each-layer: false
to_upper: normalized_weighted
tokenizer_type: CharLevelTokenizer
train-iters: 500000
train_micro_batch_size_per_gpu: 2
use-hyena-filter: true
use_cgcg: false
use_cgcg_mlp: false
use_cgcg_short: false
use_checkpoint_lr_scheduler: true
use_checkpoint_num_samples: true
use_fast_heads: false
use_fp8_input_projections: true
use_fp8_mlp_projections: true
use_fp8_norm: true
use_fp8_output_projections: true
use_slow_heads: false
use_srun_launcher: true
wall_clock_breakdown: false

warmup: 0.005
weight-decay: 0.1
zero_optimization:
  allgather_bucket_size: 500000000
  allgather_partitions: true
  contiguous_gradients: true
  cpu_offload: false
  overlap_comm: true
  reduce_bucket_size: 500000000
  reduce_scatter: true
  stage: 1
